{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_flower.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGcv3tTlYHVa",
        "colab_type": "code",
        "outputId": "eca3f4ff-2d55-4662-d709-b6c37209514f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Google Drive is already mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zS3-xtbYXTZ",
        "colab_type": "code",
        "outputId": "bbddaf2b-c5a7-454a-e08e-4247e20023dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if os.path.exists('/content/gdrive/My Drive/Colab Notebooks/data')==True:\n",
        "    #print('Train data downloading..')\n",
        "    #! curl 'https://raw.githubusercontent.com/unizard/2019.Spring.AI/master/data-zoo-v2.csv' -o '/content/gdrive/My Drive/Colab Notebooks/data-zoo-v2.csv'\n",
        "    print('Done..\\n')\n",
        "#else:\n",
        "    #print('File already exists \\n')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done..\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnFu9IVLbfE",
        "colab_type": "code",
        "outputId": "7fbef5f9-169e-4311-803c-d129e72377d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from numpy import array\n",
        " \n",
        "TRAIN_DIR = '/content/gdrive/My Drive/Colab Notebooks/data'\n",
        "train_folder_list = array(os.listdir('/content/gdrive/My Drive/Colab Notebooks/data'))\n",
        " \n",
        "train_input = []\n",
        "train_label = []\n",
        " \n",
        "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
        "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
        "onehot_encoder = OneHotEncoder(sparse=False) \n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        " \n",
        "for index in range(len(train_folder_list)):\n",
        "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
        "    path = path + '/'\n",
        "    img_list = os.listdir(path)\n",
        "    for img in img_list:\n",
        "        img_path = os.path.join(path, img)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        train_input.append([np.array(img)])\n",
        "        train_label.append([np.array(onehot_encoded[index])])\n",
        " \n",
        "train_input = np.reshape(train_input, (-1, 784))\n",
        "train_label = np.reshape(train_label, (-1, 10))\n",
        "train_input = np.array(train_input).astype(np.float32)\n",
        "train_label = np.array(train_label).astype(np.float32)\n",
        "np.save(\"train_data.npy\", train_input)\n",
        "np.save(\"train_label.npy\", train_label)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrl-q3aBlftf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "6f6ab2c3-eafb-4abe-fd92-13d0e337efb2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "print(train_input)\n",
        "train_input= MinMaxScaler().fit_transform(train_input)\n",
        "\n",
        "\n",
        "print(train_input)\n",
        "\"\"\"\n",
        "mean = train_input.mean(axis=0)\n",
        "std = train_input.std(axis=0)\n",
        "train_input = (train_input - mean) / std\n",
        "\n",
        "print(train_input)\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 63.  73.  62. ...  98.  90.  87.]\n",
            " [180. 183. 194. ...  70.  46.  42.]\n",
            " [149. 166. 169. ... 118. 127. 116.]\n",
            " ...\n",
            " [143. 135. 140. ... 166. 126.  46.]\n",
            " [186. 190. 206. ... 249. 252. 253.]\n",
            " [213. 214. 215. ... 186. 184. 183.]]\n",
            "[[0.24705884 0.28627452 0.24313727 ... 0.38431376 0.3529412  0.34117648]\n",
            " [0.7058824  0.7176471  0.7607844  ... 0.27450982 0.18039216 0.16470589]\n",
            " [0.58431375 0.6509804  0.6627451  ... 0.46274513 0.49803925 0.454902  ]\n",
            " ...\n",
            " [0.56078434 0.5294118  0.54901963 ... 0.6509804  0.49411768 0.18039216]\n",
            " [0.7294118  0.74509805 0.8078432  ... 0.97647065 0.98823535 0.9921569 ]\n",
            " [0.8352942  0.83921576 0.8431373  ... 0.7294118  0.72156864 0.7176471 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmean = train_input.mean(axis=0)\\nstd = train_input.std(axis=0)\\ntrain_input = (train_input - mean) / std\\n\\nprint(train_input)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPc_DO1NnD1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0c278fc3-8cfc-48d2-9205-3cfa02a6e6c7"
      },
      "source": [
        "\n",
        "import random\n",
        "tmp = [[x,y] for x, y in zip(train_input, train_label)]\n",
        "random.shuffle(tmp)\n",
        "data = np.reshape(tmp,(-1)) \n",
        "x_train = [n[0] for n in tmp]\n",
        "y_train = [n[1] for n in tmp]\n",
        "\n",
        "train_input = np.reshape(x_train, (-1, 784))\n",
        "train_label = np.reshape(y_train, (-1, 10))\n",
        "\n",
        "train_input=train_input[:10000]\n",
        "train_label=train_label[:10000]\n",
        "print(train_input.shape)\n",
        "print(train_label.shape)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5Dp7F9mKtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "3ee4971c-bf5d-44f8-987f-2755471706fc"
      },
      "source": [
        "learning_rate=1e-3\n",
        "training_epochs=60\n",
        "batch_size=100\n",
        "\n",
        "keep_prob=tf.placeholder(tf.float32)\n",
        "\n",
        "X=tf.placeholder(tf.float32,[None,784])\n",
        "X_img=tf.reshape(X,[-1,28,28,1])\n",
        "Y=tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "W1=tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01))\n",
        "L1=tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
        "L1=tf.nn.relu(L1)\n",
        "L1=tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "L1=tf.nn.dropout(L1,keep_prob=keep_prob)\n",
        "\n",
        "W2=tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))\n",
        "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
        "L21=tf.nn.relu(L2)\n",
        "L2=tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "L2=tf.nn.dropout(L2,keep_prob=keep_prob)\n",
        "\n",
        "W3=tf.Variable(tf.random_normal([3,3,64,128],stddev=0.01))\n",
        "L3=tf.nn.conv2d(L2,W3,strides=[1,1,1,1],padding='SAME')\n",
        "L3=tf.nn.relu(L3)\n",
        "L3=tf.nn.max_pool(L3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "L3=tf.nn.dropout(L3,keep_prob=keep_prob)\n",
        "flat_L3=tf.reshape(L3,[-1,4*4*128])\n",
        "\n",
        "W4=tf.get_variable('W4',shape=[4*4*128,625],initializer=tf.contrib.layers.xavier_initializer())\n",
        "b4=tf.Variable(tf.random_normal([625]))\n",
        "L4=tf.nn.relu(tf.matmul(flat_L3,W4)+b4)\n",
        "L4=tf.nn.dropout(L4,keep_prob=keep_prob)\n",
        "\n",
        "W5=tf.get_variable('W5',shape=[625,10],initializer=tf.contrib.layers.xavier_initializer())\n",
        "b5=tf.Variable(tf.random_normal([10]))\n",
        "\n",
        "logits=tf.matmul(L4,W5)+b5\n",
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y))\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-6-8fd6bd4bb166>:15: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-8fd6bd4bb166>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suqw_4x6mPHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1137
        },
        "outputId": "25cbc47e-691f-41f6-b9de-15efc2bc8c0d"
      },
      "source": [
        "x_batch=train_input\n",
        "y_batch=train_label\n",
        "\n",
        "print(x_batch.shape)\n",
        "print(y_batch.shape)\n",
        "\n",
        "print('start')\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost=0\n",
        "  a=0\n",
        "  total_batch=int(10000/batch_size)\n",
        "  for i in range(total_batch):\n",
        "    \n",
        "    c,_=sess.run([cost,optimizer],feed_dict={X:x_batch[a:a+batch_size],Y:y_batch[a:a+batch_size],keep_prob:0.7})\n",
        "    a = a + batch_size\n",
        "\n",
        "    avg_cost+=c/total_batch\n",
        "  print('Epoch:','%04d' %(epoch+1),'cost=','{:.9f}'.format(avg_cost))\n",
        "print('finish')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(10000, 10)\n",
            "start\n",
            "Epoch: 0001 cost= 2.421127188\n",
            "Epoch: 0002 cost= 2.212728181\n",
            "Epoch: 0003 cost= 2.070234253\n",
            "Epoch: 0004 cost= 1.953218075\n",
            "Epoch: 0005 cost= 1.856250610\n",
            "Epoch: 0006 cost= 1.765561577\n",
            "Epoch: 0007 cost= 1.679401360\n",
            "Epoch: 0008 cost= 1.612296209\n",
            "Epoch: 0009 cost= 1.548886586\n",
            "Epoch: 0010 cost= 1.491718993\n",
            "Epoch: 0011 cost= 1.427220143\n",
            "Epoch: 0012 cost= 1.361480595\n",
            "Epoch: 0013 cost= 1.320330094\n",
            "Epoch: 0014 cost= 1.272182001\n",
            "Epoch: 0015 cost= 1.213175397\n",
            "Epoch: 0016 cost= 1.159733145\n",
            "Epoch: 0017 cost= 1.119609242\n",
            "Epoch: 0018 cost= 1.080214397\n",
            "Epoch: 0019 cost= 1.061179734\n",
            "Epoch: 0020 cost= 1.001228926\n",
            "Epoch: 0021 cost= 0.955987942\n",
            "Epoch: 0022 cost= 0.932799187\n",
            "Epoch: 0023 cost= 0.885009645\n",
            "Epoch: 0024 cost= 0.852186059\n",
            "Epoch: 0025 cost= 0.842143604\n",
            "Epoch: 0026 cost= 0.813428723\n",
            "Epoch: 0027 cost= 0.800975687\n",
            "Epoch: 0028 cost= 0.770998178\n",
            "Epoch: 0029 cost= 0.733774040\n",
            "Epoch: 0030 cost= 0.704684474\n",
            "Epoch: 0031 cost= 0.681035911\n",
            "Epoch: 0032 cost= 0.667236988\n",
            "Epoch: 0033 cost= 0.623721903\n",
            "Epoch: 0034 cost= 0.610824104\n",
            "Epoch: 0035 cost= 0.614637709\n",
            "Epoch: 0036 cost= 0.584789942\n",
            "Epoch: 0037 cost= 0.550564205\n",
            "Epoch: 0038 cost= 0.534205990\n",
            "Epoch: 0039 cost= 0.539638645\n",
            "Epoch: 0040 cost= 0.519520813\n",
            "Epoch: 0041 cost= 0.511933265\n",
            "Epoch: 0042 cost= 0.471168913\n",
            "Epoch: 0043 cost= 0.473972013\n",
            "Epoch: 0044 cost= 0.456099683\n",
            "Epoch: 0045 cost= 0.462200313\n",
            "Epoch: 0046 cost= 0.459743729\n",
            "Epoch: 0047 cost= 0.429399544\n",
            "Epoch: 0048 cost= 0.424118362\n",
            "Epoch: 0049 cost= 0.404127311\n",
            "Epoch: 0050 cost= 0.412269386\n",
            "Epoch: 0051 cost= 0.388845351\n",
            "Epoch: 0052 cost= 0.400937358\n",
            "Epoch: 0053 cost= 0.383645944\n",
            "Epoch: 0054 cost= 0.376683242\n",
            "Epoch: 0055 cost= 0.366619307\n",
            "Epoch: 0056 cost= 0.355862090\n",
            "Epoch: 0057 cost= 0.334987313\n",
            "Epoch: 0058 cost= 0.329408247\n",
            "Epoch: 0059 cost= 0.346206958\n",
            "Epoch: 0060 cost= 0.357802204\n",
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lcdMepwKWvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}